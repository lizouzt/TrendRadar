"""
TrendRadar MCP Server - FastMCP 2.0 å®ç°

ä½¿ç”¨ FastMCP 2.0 æä¾›ç”Ÿäº§çº§ MCP å·¥å…·æœåŠ¡å™¨ã€‚
æ”¯æŒ stdio å’Œ HTTP ä¸¤ç§ä¼ è¾“æ¨¡å¼ã€‚
"""

import os
import json
from typing import List, Optional, Dict

from starlette.requests import Request
from starlette.responses import JSONResponse
from fastmcp import FastMCP

from .tools.data_query import DataQueryTools
from .tools.analytics import AnalyticsTools
from .tools.search_tools import SearchTools
from .tools.config_mgmt import ConfigManagementTools
from .tools.system import SystemManagementTools


# åˆ›å»º FastMCP 2.0 åº”ç”¨
mcp = FastMCP('trendradar-news')

# ä»ç¯å¢ƒå˜é‡è¯»å–é¢„è®¾çš„å¯†ç 
# è¿™ä¸ªå¯†ç ç”± start-http.bat æˆ– start-http.sh è„šæœ¬è®¾ç½®
SERVER_PASSWORD = os.getenv("MCP_SERVER_PASSWORD")


async def authentication_middleware(request: Request, call_next):
    """
    å¯†ç è®¤è¯ä¸­é—´ä»¶ - éªŒè¯HTTPè¯·æ±‚ä¸­çš„å¯†ç 
    
    ä»…åœ¨HTTPæ¨¡å¼ä¸‹ç”Ÿæ•ˆã€‚å½“MCP_SERVER_PASSWORDç¯å¢ƒå˜é‡è¢«è®¾ç½®æ—¶ï¼Œ
    æ‰€æœ‰è¯·æ±‚éƒ½å¿…é¡»åœ¨URLæŸ¥è¯¢å‚æ•°ä¸­æä¾›æ­£ç¡®çš„å¯†ç ï¼Œå¦åˆ™è¿”å›403é”™è¯¯ã€‚
    
    å¯†ç å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¼ é€’ï¼š
    - URLæŸ¥è¯¢å‚æ•°ï¼šhttp://localhost:3333/mcp?pwd=<password>
    - X-MCP-Passwordè¯·æ±‚å¤´ï¼šcurl -H "X-MCP-Password: <password>" http://localhost:3333/mcp
    """
    # ä»…å½“æœåŠ¡å™¨è®¾ç½®äº†å¯†ç æ—¶æ‰å¯ç”¨éªŒè¯
    if SERVER_PASSWORD:
        # ä¼˜å…ˆå°è¯•ä»è¯·æ±‚å¤´è·å–å¯†ç 
        password_from_header = request.headers.get("X-MCP-Password")
        
        # å…¶æ¬¡ä»URLæŸ¥è¯¢å‚æ•°è·å–å¯†ç 
        password_from_query = request.query_params.get("pwd")
        
        # è·å–å®¢æˆ·ç«¯æä¾›çš„å¯†ç ï¼ˆä¼˜å…ˆä½¿ç”¨è¯·æ±‚å¤´ï¼‰
        client_password = password_from_header or password_from_query
        
        # å¦‚æœå¯†ç ä¸æ­£ç¡®æˆ–æœªæä¾›ï¼Œåˆ™è¿”å› 403 Forbidden é”™è¯¯
        if client_password != SERVER_PASSWORD:
            return JSONResponse(
                status_code=403,
                content={
                    "error": "Forbidden",
                    "message": "Invalid or missing password. Please provide 'pwd' query parameter or 'X-MCP-Password' header."
                },
            )
    
    # å¦‚æœå¯†ç æ­£ç¡®æˆ–æœåŠ¡å™¨æœªè®¾ç½®å¯†ç ï¼Œåˆ™ç»§ç»­å¤„ç†è¯·æ±‚
    response = await call_next(request)
    return response


# æ³¨å†Œè®¤è¯ä¸­é—´ä»¶
mcp.add_middleware(authentication_middleware)

# å…¨å±€å·¥å…·å®ä¾‹ï¼ˆåœ¨ç¬¬ä¸€æ¬¡è¯·æ±‚æ—¶åˆå§‹åŒ–ï¼‰
_tools_instances = {}


def _get_tools(project_root: Optional[str] = None):
    """è·å–æˆ–åˆ›å»ºå·¥å…·å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    if not _tools_instances:
        _tools_instances['data'] = DataQueryTools(project_root)
        _tools_instances['analytics'] = AnalyticsTools(project_root)
        _tools_instances['search'] = SearchTools(project_root)
        _tools_instances['config'] = ConfigManagementTools(project_root)
        _tools_instances['system'] = SystemManagementTools(project_root)
    return _tools_instances


# ==================== æ•°æ®æŸ¥è¯¢å·¥å…· ====================

@mcp.tool
async def get_latest_news(
    platforms: Optional[List[str]] = None,
    limit: int = 50,
    include_url: bool = False
) -> str:
    """
    è·å–æœ€æ–°ä¸€æ‰¹çˆ¬å–çš„æ–°é—»æ•°æ®ï¼Œå¿«é€Ÿäº†è§£å½“å‰çƒ­ç‚¹

    Args:
        platforms: å¹³å°IDåˆ—è¡¨ï¼Œå¦‚ ['zhihu', 'weibo', 'douyin']
                   - ä¸æŒ‡å®šæ—¶ï¼šä½¿ç”¨ config.yaml ä¸­é…ç½®çš„æ‰€æœ‰å¹³å°
                   - æ”¯æŒçš„å¹³å°æ¥è‡ª config/config.yaml çš„ platforms é…ç½®
                   - æ¯ä¸ªå¹³å°éƒ½æœ‰å¯¹åº”çš„nameå­—æ®µï¼ˆå¦‚"çŸ¥ä¹"ã€"å¾®åš"ï¼‰ï¼Œæ–¹ä¾¿AIè¯†åˆ«
        limit: è¿”å›æ¡æ•°é™åˆ¶ï¼Œé»˜è®¤50ï¼Œæœ€å¤§1000
               æ³¨æ„ï¼šå®é™…è¿”å›æ•°é‡å¯èƒ½å°‘äºè¯·æ±‚å€¼ï¼Œå–å†³äºå½“å‰å¯ç”¨çš„æ–°é—»æ€»æ•°
        include_url: æ˜¯å¦åŒ…å«URLé“¾æ¥ï¼Œé»˜è®¤Falseï¼ˆèŠ‚çœtokenï¼‰

    Returns:
        JSONæ ¼å¼çš„æ–°é—»åˆ—è¡¨

    **é‡è¦ï¼šæ•°æ®å±•ç¤ºå»ºè®®**
    æœ¬å·¥å…·ä¼šè¿”å›å®Œæ•´çš„æ–°é—»åˆ—è¡¨ï¼ˆé€šå¸¸50æ¡ï¼‰ç»™ä½ ã€‚ä½†è¯·æ³¨æ„ï¼š
    - **å·¥å…·è¿”å›**ï¼šå®Œæ•´çš„50æ¡æ•°æ® âœ…
    - **å»ºè®®å±•ç¤º**ï¼šå‘ç”¨æˆ·å±•ç¤ºå…¨éƒ¨æ•°æ®ï¼Œé™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚æ€»ç»“
    - **ç”¨æˆ·æœŸæœ›**ï¼šç”¨æˆ·å¯èƒ½éœ€è¦å®Œæ•´æ•°æ®ï¼Œè¯·è°¨æ…æ€»ç»“

    **ä½•æ—¶å¯ä»¥æ€»ç»“**ï¼š
    - ç”¨æˆ·æ˜ç¡®è¯´"ç»™æˆ‘æ€»ç»“ä¸€ä¸‹"æˆ–"æŒ‘é‡ç‚¹è¯´"
    - æ•°æ®é‡è¶…è¿‡100æ¡æ—¶ï¼Œå¯å…ˆå±•ç¤ºéƒ¨åˆ†å¹¶è¯¢é—®æ˜¯å¦æŸ¥çœ‹å…¨éƒ¨

    **æ³¨æ„**ï¼šå¦‚æœç”¨æˆ·è¯¢é—®"ä¸ºä»€ä¹ˆåªæ˜¾ç¤ºäº†éƒ¨åˆ†"ï¼Œè¯´æ˜ä»–ä»¬éœ€è¦å®Œæ•´æ•°æ®
    """
    tools = _get_tools()
    result = tools['data'].get_latest_news(platforms=platforms, limit=limit, include_url=include_url)
    return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool
async def get_trending_topics(
    top_n: int = 10,
    mode: str = 'current'
) -> str:
    """
    è·å–ä¸ªäººå…³æ³¨è¯çš„æ–°é—»å‡ºç°é¢‘ç‡ç»Ÿè®¡ï¼ˆåŸºäº config/frequency_words.txtï¼‰

    æ³¨æ„ï¼šæœ¬å·¥å…·ä¸æ˜¯è‡ªåŠ¨æå–æ–°é—»çƒ­ç‚¹ï¼Œè€Œæ˜¯ç»Ÿè®¡ä½ åœ¨ config/frequency_words.txt ä¸­
    è®¾ç½®çš„ä¸ªäººå…³æ³¨è¯åœ¨æ–°é—»ä¸­å‡ºç°çš„é¢‘ç‡ã€‚ä½ å¯ä»¥è‡ªå®šä¹‰è¿™ä¸ªå…³æ³¨è¯åˆ—è¡¨ã€‚

    Args:
        top_n: è¿”å›TOP Nå…³æ³¨è¯ï¼Œé»˜è®¤10
        mode: æ¨¡å¼é€‰æ‹©
            - daily: å½“æ—¥ç´¯è®¡æ•°æ®ç»Ÿè®¡
            - current: æœ€æ–°ä¸€æ‰¹æ•°æ®ç»Ÿè®¡ï¼ˆé»˜è®¤ï¼‰

    Returns:
        JSONæ ¼å¼çš„å…³æ³¨è¯é¢‘ç‡ç»Ÿè®¡åˆ—è¡¨
    """
    tools = _get_tools()
    result = tools['data'].get_trending_topics(top_n=top_n, mode=mode)
    return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool
async def get_news_by_date(
    date_query: Optional[str] = None,
    platforms: Optional[List[str]] = None,
    limit: int = 50,
    include_url: bool = False
) -> str:
    """
    è·å–æŒ‡å®šæ—¥æœŸçš„æ–°é—»æ•°æ®ï¼Œç”¨äºå†å²æ•°æ®åˆ†æå’Œå¯¹æ¯”

    Args:
        date_query: æ—¥æœŸæŸ¥è¯¢ï¼Œå¯é€‰æ ¼å¼:
            - è‡ªç„¶è¯­è¨€: "ä»Šå¤©", "æ˜¨å¤©", "å‰å¤©", "3å¤©å‰"
            - æ ‡å‡†æ—¥æœŸ: "2024-01-15", "2024/01/15"
            - é»˜è®¤å€¼: "ä»Šå¤©"ï¼ˆèŠ‚çœtokenï¼‰
        platforms: å¹³å°IDåˆ—è¡¨ï¼Œå¦‚ ['zhihu', 'weibo', 'douyin']
                   - ä¸æŒ‡å®šæ—¶ï¼šä½¿ç”¨ config.yaml ä¸­é…ç½®çš„æ‰€æœ‰å¹³å°
                   - æ”¯æŒçš„å¹³å°æ¥è‡ª config/config.yaml çš„ platforms é…ç½®
                   - æ¯ä¸ªå¹³å°éƒ½æœ‰å¯¹åº”çš„nameå­—æ®µï¼ˆå¦‚"çŸ¥ä¹"ã€"å¾®åš"ï¼‰ï¼Œæ–¹ä¾¿AIè¯†åˆ«
        limit: è¿”å›æ¡æ•°é™åˆ¶ï¼Œé»˜è®¤50ï¼Œæœ€å¤§1000
               æ³¨æ„ï¼šå®é™…è¿”å›æ•°é‡å¯èƒ½å°‘äºè¯·æ±‚å€¼ï¼Œå–å†³äºæŒ‡å®šæ—¥æœŸçš„æ–°é—»æ€»æ•°
        include_url: æ˜¯å¦åŒ…å«URLé“¾æ¥ï¼Œé»˜è®¤Falseï¼ˆèŠ‚çœtokenï¼‰

    Returns:
        JSONæ ¼å¼çš„æ–°é—»åˆ—è¡¨ï¼ŒåŒ…å«æ ‡é¢˜ã€å¹³å°ã€æ’åç­‰ä¿¡æ¯

    **é‡è¦ï¼šæ•°æ®å±•ç¤ºå»ºè®®**
    æœ¬å·¥å…·ä¼šè¿”å›å®Œæ•´çš„æ–°é—»åˆ—è¡¨ï¼ˆé€šå¸¸50æ¡ï¼‰ç»™ä½ ã€‚ä½†è¯·æ³¨æ„ï¼š
    - **å·¥å…·è¿”å›**ï¼šå®Œæ•´çš„50æ¡æ•°æ® âœ…
    - **å»ºè®®å±•ç¤º**ï¼šå‘ç”¨æˆ·å±•ç¤ºå…¨éƒ¨æ•°æ®ï¼Œé™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚æ€»ç»“
    - **ç”¨æˆ·æœŸæœ›**ï¼šç”¨æˆ·å¯èƒ½éœ€è¦å®Œæ•´æ•°æ®ï¼Œè¯·è°¨æ…æ€»ç»“

    **ä½•æ—¶å¯ä»¥æ€»ç»“**ï¼š
    - ç”¨æˆ·æ˜ç¡®è¯´"ç»™æˆ‘æ€»ç»“ä¸€ä¸‹"æˆ–"æŒ‘é‡ç‚¹è¯´"
    - æ•°æ®é‡è¶…è¿‡100æ¡æ—¶ï¼Œå¯å…ˆå±•ç¤ºéƒ¨åˆ†å¹¶è¯¢é—®æ˜¯å¦æŸ¥çœ‹å…¨éƒ¨

    **æ³¨æ„**ï¼šå¦‚æœç”¨æˆ·è¯¢é—®"ä¸ºä»€ä¹ˆåªæ˜¾ç¤ºäº†éƒ¨åˆ†"ï¼Œè¯´æ˜ä»–ä»¬éœ€è¦å®Œæ•´æ•°æ®
    """
    tools = _get_tools()
    result = tools['data'].get_news_by_date(
        date_query=date_query,
        platforms=platforms,
        limit=limit,
        include_url=include_url
    )
    return json.dumps(result, ensure_ascii=False, indent=2)



# ==================== é«˜çº§æ•°æ®åˆ†æå·¥å…· ====================

@mcp.tool
async def analyze_topic_trend(
    topic: str,
    analysis_type: str = "trend",
    date_range: Optional[Dict[str, str]] = None,
    granularity: str = "day",
    threshold: float = 3.0,
    time_window: int = 24,
    lookahead_hours: int = 6,
    confidence_threshold: float = 0.7
) -> str:
    """
    ç»Ÿä¸€è¯é¢˜è¶‹åŠ¿åˆ†æå·¥å…· - æ•´åˆå¤šç§è¶‹åŠ¿åˆ†ææ¨¡å¼

    Args:
        topic: è¯é¢˜å…³é”®è¯ï¼ˆå¿…éœ€ï¼‰
        analysis_type: åˆ†æç±»å‹ï¼Œå¯é€‰å€¼ï¼š
            - "trend": çƒ­åº¦è¶‹åŠ¿åˆ†æï¼ˆè¿½è¸ªè¯é¢˜çš„çƒ­åº¦å˜åŒ–ï¼‰
            - "lifecycle": ç”Ÿå‘½å‘¨æœŸåˆ†æï¼ˆä»å‡ºç°åˆ°æ¶ˆå¤±çš„å®Œæ•´å‘¨æœŸï¼‰
            - "viral": å¼‚å¸¸çƒ­åº¦æ£€æµ‹ï¼ˆè¯†åˆ«çªç„¶çˆ†ç«çš„è¯é¢˜ï¼‰
            - "predict": è¯é¢˜é¢„æµ‹ï¼ˆé¢„æµ‹æœªæ¥å¯èƒ½çš„çƒ­ç‚¹ï¼‰
        date_range: æ—¥æœŸèŒƒå›´ï¼ˆtrendå’Œlifecycleæ¨¡å¼ï¼‰ï¼Œå¯é€‰
                    - **æ ¼å¼**: {"start": "YYYY-MM-DD", "end": "YYYY-MM-DD"}
                    - **ç¤ºä¾‹**: {"start": "2025-10-18", "end": "2025-10-25"}
                    - **è¯´æ˜**: AIéœ€è¦æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€ï¼ˆå¦‚"æœ€è¿‘7å¤©"ï¼‰è‡ªåŠ¨è®¡ç®—æ—¥æœŸèŒƒå›´
                    - **é»˜è®¤**: ä¸æŒ‡å®šæ—¶é»˜è®¤åˆ†ææœ€è¿‘7å¤©
        granularity: æ—¶é—´ç²’åº¦ï¼ˆtrendæ¨¡å¼ï¼‰ï¼Œé»˜è®¤"day"ï¼ˆä»…æ”¯æŒ dayï¼Œå› ä¸ºåº•å±‚æ•°æ®æŒ‰å¤©èšåˆï¼‰
        threshold: çƒ­åº¦çªå¢å€æ•°é˜ˆå€¼ï¼ˆviralæ¨¡å¼ï¼‰ï¼Œé»˜è®¤3.0
        time_window: æ£€æµ‹æ—¶é—´çª—å£å°æ—¶æ•°ï¼ˆviralæ¨¡å¼ï¼‰ï¼Œé»˜è®¤24
        lookahead_hours: é¢„æµ‹æœªæ¥å°æ—¶æ•°ï¼ˆpredictæ¨¡å¼ï¼‰ï¼Œé»˜è®¤6
        confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆpredictæ¨¡å¼ï¼‰ï¼Œé»˜è®¤0.7

    Returns:
        JSONæ ¼å¼çš„è¶‹åŠ¿åˆ†æç»“æœ

    **AIä½¿ç”¨è¯´æ˜ï¼š**
    å½“ç”¨æˆ·ä½¿ç”¨ç›¸å¯¹æ—¶é—´è¡¨è¾¾æ—¶ï¼ˆå¦‚"æœ€è¿‘7å¤©"ã€"è¿‡å»ä¸€å‘¨"ã€"ä¸Šä¸ªæœˆ"ï¼‰ï¼Œ
    AIéœ€è¦è‡ªåŠ¨è®¡ç®—å¯¹åº”çš„æ—¥æœŸèŒƒå›´å¹¶ä¼ é€’ç»™ date_range å‚æ•°ã€‚

    Examples:
        - analyze_topic_trend(topic="äººå·¥æ™ºèƒ½", analysis_type="trend", date_range={"start": "2025-10-18", "end": "2025-10-25"})
        - analyze_topic_trend(topic="ç‰¹æ–¯æ‹‰", analysis_type="lifecycle", date_range={"start": "2025-10-18", "end": "2025-10-25"})
        - analyze_topic_trend(topic="æ¯”ç‰¹å¸", analysis_type="viral", threshold=3.0)
        - analyze_topic_trend(topic="ChatGPT", analysis_type="predict", lookahead_hours=6)
    """
    tools = _get_tools()
    result = tools['analytics'].analyze_topic_trend_unified(
        topic=topic,
        analysis_type=analysis_type,
        date_range=date_range,
        granularity=granularity,
        threshold=threshold,
        time_window=time_window,
        lookahead_hours=lookahead_hours,
        confidence_threshold=confidence_threshold
    )
    return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool
async def analyze_data_insights(
    insight_type: str = "platform_compare",
    topic: Optional[str] = None,
    date_range: Optional[Dict[str, str]] = None,
    min_frequency: int = 3,
    top_n: int = 20
) -> str:
    """
    ç»Ÿä¸€æ•°æ®æ´å¯Ÿåˆ†æå·¥å…· - æ•´åˆå¤šç§æ•°æ®åˆ†ææ¨¡å¼

    Args:
        insight_type: æ´å¯Ÿç±»å‹ï¼Œå¯é€‰å€¼ï¼š
            - "platform_compare": å¹³å°å¯¹æ¯”åˆ†æï¼ˆå¯¹æ¯”ä¸åŒå¹³å°å¯¹è¯é¢˜çš„å…³æ³¨åº¦ï¼‰
            - "platform_activity": å¹³å°æ´»è·ƒåº¦ç»Ÿè®¡ï¼ˆç»Ÿè®¡å„å¹³å°å‘å¸ƒé¢‘ç‡å’Œæ´»è·ƒæ—¶é—´ï¼‰
            - "keyword_cooccur": å…³é”®è¯å…±ç°åˆ†æï¼ˆåˆ†æå…³é”®è¯åŒæ—¶å‡ºç°çš„æ¨¡å¼ï¼‰
        topic: è¯é¢˜å…³é”®è¯ï¼ˆå¯é€‰ï¼Œplatform_compareæ¨¡å¼é€‚ç”¨ï¼‰
        date_range: **ã€å¯¹è±¡ç±»å‹ã€‘** æ—¥æœŸèŒƒå›´ï¼ˆå¯é€‰ï¼‰
                    - **æ ¼å¼**: {"start": "YYYY-MM-DD", "end": "YYYY-MM-DD"}
                    - **ç¤ºä¾‹**: {"start": "2025-01-01", "end": "2025-01-07"}
                    - **é‡è¦**: å¿…é¡»æ˜¯å¯¹è±¡æ ¼å¼ï¼Œä¸èƒ½ä¼ é€’æ•´æ•°
        min_frequency: æœ€å°å…±ç°é¢‘æ¬¡ï¼ˆkeyword_cooccuræ¨¡å¼ï¼‰ï¼Œé»˜è®¤3
        top_n: è¿”å›TOP Nç»“æœï¼ˆkeyword_cooccuræ¨¡å¼ï¼‰ï¼Œé»˜è®¤20

    Returns:
        JSONæ ¼å¼çš„æ•°æ®æ´å¯Ÿåˆ†æç»“æœ

    Examples:
        - analyze_data_insights(insight_type="platform_compare", topic="äººå·¥æ™ºèƒ½")
        - analyze_data_insights(insight_type="platform_activity", date_range={"start": "2025-01-01", "end": "2025-01-07"})
        - analyze_data_insights(insight_type="keyword_cooccur", min_frequency=5, top_n=15)
    """
    tools = _get_tools()
    result = tools['analytics'].analyze_data_insights_unified(
        insight_type=insight_type,
        topic=topic,
        date_range=date_range,
        min_frequency=min_frequency,
        top_n=top_n
    )
    return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool
async def analyze_sentiment(
    topic: Optional[str] = None,
    platforms: Optional[List[str]] = None,
    date_range: Optional[Dict[str, str]] = None,
    limit: int = 50,
    sort_by_weight: bool = True,
    include_url: bool = False
) -> str:
    """
    åˆ†ææ–°é—»çš„æƒ…æ„Ÿå€¾å‘å’Œçƒ­åº¦è¶‹åŠ¿

    Args:
        topic: è¯é¢˜å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
        platforms: å¹³å°IDåˆ—è¡¨ï¼Œå¦‚ ['zhihu', 'weibo', 'douyin']
                   - ä¸æŒ‡å®šæ—¶ï¼šä½¿ç”¨ config.yaml ä¸­é…ç½®çš„æ‰€æœ‰å¹³å°
                   - æ”¯æŒçš„å¹³å°æ¥è‡ª config/config.yaml çš„ platforms é…ç½®
                   - æ¯ä¸ªå¹³å°éƒ½æœ‰å¯¹åº”çš„nameå­—æ®µï¼ˆå¦‚"çŸ¥ä¹"ã€"å¾®åš"ï¼‰ï¼Œæ–¹ä¾¿AIè¯†åˆ«
        date_range: **ã€å¯¹è±¡ç±»å‹ã€‘** æ—¥æœŸèŒƒå›´ï¼ˆå¯é€‰ï¼‰
                    - **æ ¼å¼**: {"start": "YYYY-MM-DD", "end": "YYYY-MM-DD"}
                    - **ç¤ºä¾‹**: {"start": "2025-01-01", "end": "2025-01-07"}
                    - **é‡è¦**: å¿…é¡»æ˜¯å¯¹è±¡æ ¼å¼ï¼Œä¸èƒ½ä¼ é€’æ•´æ•°
        limit: è¿”å›æ–°é—»æ•°é‡ï¼Œé»˜è®¤50ï¼Œæœ€å¤§100
               æ³¨æ„ï¼šæœ¬å·¥å…·ä¼šå¯¹æ–°é—»æ ‡é¢˜è¿›è¡Œå»é‡ï¼ˆåŒä¸€æ ‡é¢˜åœ¨ä¸åŒå¹³å°åªä¿ç•™ä¸€æ¬¡ï¼‰ï¼Œ
               å› æ­¤å®é™…è¿”å›æ•°é‡å¯èƒ½å°‘äºè¯·æ±‚çš„ limit å€¼
        sort_by_weight: æ˜¯å¦æŒ‰çƒ­åº¦æƒé‡æ’åºï¼Œé»˜è®¤True
        include_url: æ˜¯å¦åŒ…å«URLé“¾æ¥ï¼Œé»˜è®¤Falseï¼ˆèŠ‚çœtokenï¼‰

    Returns:
        JSONæ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å«æƒ…æ„Ÿåˆ†å¸ƒã€çƒ­åº¦è¶‹åŠ¿å’Œç›¸å…³æ–°é—»

    **é‡è¦ï¼šæ•°æ®å±•ç¤ºç­–ç•¥**
    - æœ¬å·¥å…·è¿”å›å®Œæ•´çš„åˆ†æç»“æœå’Œæ–°é—»åˆ—è¡¨
    - **é»˜è®¤å±•ç¤ºæ–¹å¼**ï¼šå±•ç¤ºå®Œæ•´çš„åˆ†æç»“æœï¼ˆåŒ…æ‹¬æ‰€æœ‰æ–°é—»ï¼‰
    - ä»…åœ¨ç”¨æˆ·æ˜ç¡®è¦æ±‚"æ€»ç»“"æˆ–"æŒ‘é‡ç‚¹"æ—¶æ‰è¿›è¡Œç­›é€‰
    """
    tools = _get_tools()
    result = tools['analytics'].analyze_sentiment(
        topic=topic,
        platforms=platforms,
        date_range=date_range,
        limit=limit,
        sort_by_weight=sort_by_weight,
        include_url=include_url
    )
    return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool
async def find_similar_news(
    reference_title: str,
    threshold: float = 0.6,
    limit: int = 50,
    include_url: bool = False
) -> str:
    """
    æŸ¥æ‰¾ä¸æŒ‡å®šæ–°é—»æ ‡é¢˜ç›¸ä¼¼çš„å…¶ä»–æ–°é—»

    Args:
        reference_title: æ–°é—»æ ‡é¢˜ï¼ˆå®Œæ•´æˆ–éƒ¨åˆ†ï¼‰
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œ0-1ä¹‹é—´ï¼Œé»˜è®¤0.6
                   æ³¨æ„ï¼šé˜ˆå€¼è¶Šé«˜åŒ¹é…è¶Šä¸¥æ ¼ï¼Œè¿”å›ç»“æœè¶Šå°‘
        limit: è¿”å›æ¡æ•°é™åˆ¶ï¼Œé»˜è®¤50ï¼Œæœ€å¤§100
               æ³¨æ„ï¼šå®é™…è¿”å›æ•°é‡å–å†³äºç›¸ä¼¼åº¦åŒ¹é…ç»“æœï¼Œå¯èƒ½å°‘äºè¯·æ±‚å€¼
        include_url: æ˜¯å¦åŒ…å«URLé“¾æ¥ï¼Œé»˜è®¤Falseï¼ˆèŠ‚çœtokenï¼‰

    Returns:
        JSONæ ¼å¼çš„ç›¸ä¼¼æ–°é—»åˆ—è¡¨ï¼ŒåŒ…å«ç›¸ä¼¼åº¦åˆ†æ•°

    **é‡è¦ï¼šæ•°æ®å±•ç¤ºç­–ç•¥**
    - æœ¬å·¥å…·è¿”å›å®Œæ•´çš„ç›¸ä¼¼æ–°é—»åˆ—è¡¨
    - **é»˜è®¤å±•ç¤ºæ–¹å¼**ï¼šå±•ç¤ºå…¨éƒ¨è¿”å›çš„æ–°é—»ï¼ˆåŒ…æ‹¬ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰
    - ä»…åœ¨ç”¨æˆ·æ˜ç¡®è¦æ±‚"æ€»ç»“"æˆ–"æŒ‘é‡ç‚¹"æ—¶æ‰è¿›è¡Œç­›é€‰
    """
    tools = _get_tools()
    result = tools['analytics'].find_similar_news(
        reference_title=reference_title,
        threshold=threshold,
        limit=limit,
        include_url=include_url
    )
    return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool
async def generate_summary_report(
    report_type: str = "daily",
    date_range: Optional[Dict[str, str]] = None
) -> str:
    """
    æ¯æ—¥/æ¯å‘¨æ‘˜è¦ç”Ÿæˆå™¨ - è‡ªåŠ¨ç”Ÿæˆçƒ­ç‚¹æ‘˜è¦æŠ¥å‘Š

    Args:
        report_type: æŠ¥å‘Šç±»å‹ï¼ˆdaily/weeklyï¼‰
        date_range: **ã€å¯¹è±¡ç±»å‹ã€‘** è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´ï¼ˆå¯é€‰ï¼‰
                    - **æ ¼å¼**: {"start": "YYYY-MM-DD", "end": "YYYY-MM-DD"}
                    - **ç¤ºä¾‹**: {"start": "2025-01-01", "end": "2025-01-07"}
                    - **é‡è¦**: å¿…é¡»æ˜¯å¯¹è±¡æ ¼å¼ï¼Œä¸èƒ½ä¼ é€’æ•´æ•°

    Returns:
        JSONæ ¼å¼çš„æ‘˜è¦æŠ¥å‘Šï¼ŒåŒ…å«Markdownæ ¼å¼å†…å®¹
    """
    tools = _get_tools()
    result = tools['analytics'].generate_summary_report(
        report_type=report_type,
        date_range=date_range
    )
    return json.dumps(result, ensure_ascii=False, indent=2)


# ==================== æ™ºèƒ½æ£€ç´¢å·¥å…· ====================

@mcp.tool
async def search_news(
    query: str,
    search_mode: str = "keyword",
    date_range: Optional[Dict[str, str]] = None,
    platforms: Optional[List[str]] = None,
    limit: int = 50,
    sort_by: str = "relevance",
    threshold: float = 0.6,
    include_url: bool = False
) -> str:
    """
    ç»Ÿä¸€æœç´¢æ¥å£ï¼Œæ”¯æŒå¤šç§æœç´¢æ¨¡å¼

    Args:
        query: æœç´¢å…³é”®è¯æˆ–å†…å®¹ç‰‡æ®µ
        search_mode: æœç´¢æ¨¡å¼ï¼Œå¯é€‰å€¼ï¼š
            - "keyword": ç²¾ç¡®å…³é”®è¯åŒ¹é…ï¼ˆé»˜è®¤ï¼Œé€‚åˆæœç´¢ç‰¹å®šè¯é¢˜ï¼‰
            - "fuzzy": æ¨¡ç³Šå†…å®¹åŒ¹é…ï¼ˆé€‚åˆæœç´¢å†…å®¹ç‰‡æ®µï¼Œä¼šè¿‡æ»¤ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼çš„ç»“æœï¼‰
            - "entity": å®ä½“åç§°æœç´¢ï¼ˆé€‚åˆæœç´¢äººç‰©/åœ°ç‚¹/æœºæ„ï¼‰
        date_range: æ—¥æœŸèŒƒå›´ï¼ˆå¯é€‰ï¼‰
                    - **æ ¼å¼**: {"start": "YYYY-MM-DD", "end": "YYYY-MM-DD"}
                    - **ç¤ºä¾‹**: {"start": "2025-01-01", "end": "2025-01-07"}
                    - **è¯´æ˜**: AIéœ€è¦æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€ï¼ˆå¦‚"æœ€è¿‘7å¤©"ï¼‰è‡ªåŠ¨è®¡ç®—æ—¥æœŸèŒƒå›´
                    - **é»˜è®¤**: ä¸æŒ‡å®šæ—¶é»˜è®¤æŸ¥è¯¢ä»Šå¤©çš„æ–°é—»
                    - **æ³¨æ„**: startå’Œendå¯ä»¥ç›¸åŒï¼ˆè¡¨ç¤ºå•æ—¥æŸ¥è¯¢ï¼‰
        platforms: å¹³å°IDåˆ—è¡¨ï¼Œå¦‚ ['zhihu', 'weibo', 'douyin']
                   - ä¸æŒ‡å®šæ—¶ï¼šä½¿ç”¨ config.yaml ä¸­é…ç½®çš„æ‰€æœ‰å¹³å°
                   - æ”¯æŒçš„å¹³å°æ¥è‡ª config/config.yaml çš„ platforms é…ç½®
                   - æ¯ä¸ªå¹³å°éƒ½æœ‰å¯¹åº”çš„nameå­—æ®µï¼ˆå¦‚"çŸ¥ä¹"ã€"å¾®åš"ï¼‰ï¼Œæ–¹ä¾¿AIè¯†åˆ«
        limit: è¿”å›æ¡æ•°é™åˆ¶ï¼Œé»˜è®¤50ï¼Œæœ€å¤§1000
               æ³¨æ„ï¼šå®é™…è¿”å›æ•°é‡å–å†³äºæœç´¢åŒ¹é…ç»“æœï¼ˆç‰¹åˆ«æ˜¯ fuzzy æ¨¡å¼ä¸‹ä¼šè¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœï¼‰
        sort_by: æ’åºæ–¹å¼ï¼Œå¯é€‰å€¼ï¼š
            - "relevance": æŒ‰ç›¸å…³åº¦æ’åºï¼ˆé»˜è®¤ï¼‰
            - "weight": æŒ‰æ–°é—»æƒé‡æ’åº
            - "date": æŒ‰æ—¥æœŸæ’åº
        threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä»…fuzzyæ¨¡å¼æœ‰æ•ˆï¼‰ï¼Œ0-1ä¹‹é—´ï¼Œé»˜è®¤0.6
                   æ³¨æ„ï¼šé˜ˆå€¼è¶Šé«˜åŒ¹é…è¶Šä¸¥æ ¼ï¼Œè¿”å›ç»“æœè¶Šå°‘
        include_url: æ˜¯å¦åŒ…å«URLé“¾æ¥ï¼Œé»˜è®¤Falseï¼ˆèŠ‚çœtokenï¼‰

    Returns:
        JSONæ ¼å¼çš„æœç´¢ç»“æœï¼ŒåŒ…å«æ ‡é¢˜ã€å¹³å°ã€æ’åç­‰ä¿¡æ¯

    **é‡è¦ï¼šæ•°æ®å±•ç¤ºç­–ç•¥**
    - æœ¬å·¥å…·è¿”å›å®Œæ•´çš„æœç´¢ç»“æœåˆ—è¡¨
    - **é»˜è®¤å±•ç¤ºæ–¹å¼**ï¼šå±•ç¤ºå…¨éƒ¨è¿”å›çš„æ–°é—»ï¼Œæ— éœ€æ€»ç»“æˆ–ç­›é€‰
    - ä»…åœ¨ç”¨æˆ·æ˜ç¡®è¦æ±‚"æ€»ç»“"æˆ–"æŒ‘é‡ç‚¹"æ—¶æ‰è¿›è¡Œç­›é€‰

    **AIä½¿ç”¨è¯´æ˜ï¼š**
    å½“ç”¨æˆ·ä½¿ç”¨ç›¸å¯¹æ—¶é—´è¡¨è¾¾æ—¶ï¼ˆå¦‚"æœ€è¿‘7å¤©"ã€"è¿‡å»ä¸€å‘¨"ã€"æœ€è¿‘åŠä¸ªæœˆ"ï¼‰ï¼Œ
    AIéœ€è¦è‡ªåŠ¨è®¡ç®—å¯¹åº”çš„æ—¥æœŸèŒƒå›´ã€‚è®¡ç®—è§„åˆ™ï¼š
    - "æœ€è¿‘7å¤©" â†’ {"start": "ä»Šå¤©-6å¤©", "end": "ä»Šå¤©"}
    - "è¿‡å»ä¸€å‘¨" â†’ {"start": "ä»Šå¤©-6å¤©", "end": "ä»Šå¤©"}
    - "æœ€è¿‘30å¤©" â†’ {"start": "ä»Šå¤©-29å¤©", "end": "ä»Šå¤©"}

    Examples:
        - ä»Šå¤©çš„æ–°é—»: search_news(query="äººå·¥æ™ºèƒ½")
        - æœ€è¿‘7å¤©: search_news(query="äººå·¥æ™ºèƒ½", date_range={"start": "2025-10-18", "end": "2025-10-25"})
        - ç²¾ç¡®æ—¥æœŸ: search_news(query="äººå·¥æ™ºèƒ½", date_range={"start": "2025-01-01", "end": "2025-01-07"})
        - æ¨¡ç³Šæœç´¢: search_news(query="ç‰¹æ–¯æ‹‰é™ä»·", search_mode="fuzzy", threshold=0.4)
    """
    tools = _get_tools()
    result = tools['search'].search_news_unified(
        query=query,
        search_mode=search_mode,
        date_range=date_range,
        platforms=platforms,
        limit=limit,
        sort_by=sort_by,
        threshold=threshold,
        include_url=include_url
    )
    return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool
async def search_related_news_history(
    reference_text: str,
    time_preset: str = "yesterday",
    threshold: float = 0.4,
    limit: int = 50,
    include_url: bool = False
) -> str:
    """
    åŸºäºç§å­æ–°é—»ï¼Œåœ¨å†å²æ•°æ®ä¸­æœç´¢ç›¸å…³æ–°é—»

    Args:
        reference_text: å‚è€ƒæ–°é—»æ ‡é¢˜ï¼ˆå®Œæ•´æˆ–éƒ¨åˆ†ï¼‰
        time_preset: æ—¶é—´èŒƒå›´é¢„è®¾å€¼ï¼Œå¯é€‰ï¼š
            - "yesterday": æ˜¨å¤©
            - "last_week": ä¸Šå‘¨ (7å¤©)
            - "last_month": ä¸Šä¸ªæœˆ (30å¤©)
            - "custom": è‡ªå®šä¹‰æ—¥æœŸèŒƒå›´ï¼ˆéœ€è¦æä¾› start_date å’Œ end_dateï¼‰
        threshold: ç›¸å…³æ€§é˜ˆå€¼ï¼Œ0-1ä¹‹é—´ï¼Œé»˜è®¤0.4
                   æ³¨æ„ï¼šç»¼åˆç›¸ä¼¼åº¦è®¡ç®—ï¼ˆ70%å…³é”®è¯é‡åˆ + 30%æ–‡æœ¬ç›¸ä¼¼åº¦ï¼‰
                   é˜ˆå€¼è¶Šé«˜åŒ¹é…è¶Šä¸¥æ ¼ï¼Œè¿”å›ç»“æœè¶Šå°‘
        limit: è¿”å›æ¡æ•°é™åˆ¶ï¼Œé»˜è®¤50ï¼Œæœ€å¤§100
               æ³¨æ„ï¼šå®é™…è¿”å›æ•°é‡å–å†³äºç›¸å…³æ€§åŒ¹é…ç»“æœï¼Œå¯èƒ½å°‘äºè¯·æ±‚å€¼
        include_url: æ˜¯å¦åŒ…å«URLé“¾æ¥ï¼Œé»˜è®¤Falseï¼ˆèŠ‚çœtokenï¼‰

    Returns:
        JSONæ ¼å¼çš„ç›¸å…³æ–°é—»åˆ—è¡¨ï¼ŒåŒ…å«ç›¸å…³æ€§åˆ†æ•°å’Œæ—¶é—´åˆ†å¸ƒ

    **é‡è¦ï¼šæ•°æ®å±•ç¤ºç­–ç•¥**
    - æœ¬å·¥å…·è¿”å›å®Œæ•´çš„ç›¸å…³æ–°é—»åˆ—è¡¨
    - **é»˜è®¤å±•ç¤ºæ–¹å¼**ï¼šå±•ç¤ºå…¨éƒ¨è¿”å›çš„æ–°é—»ï¼ˆåŒ…æ‹¬ç›¸å…³æ€§åˆ†æ•°ï¼‰
    - ä»…åœ¨ç”¨æˆ·æ˜ç¡®è¦æ±‚"æ€»ç»“"æˆ–"æŒ‘é‡ç‚¹"æ—¶æ‰è¿›è¡Œç­›é€‰
    """
    tools = _get_tools()
    result = tools['search'].search_related_news_history(
        reference_text=reference_text,
        time_preset=time_preset,
        threshold=threshold,
        limit=limit,
        include_url=include_url
    )
    return json.dumps(result, ensure_ascii=False, indent=2)


# ==================== é…ç½®ä¸ç³»ç»Ÿç®¡ç†å·¥å…· ====================

@mcp.tool
async def get_current_config(
    section: str = "all"
) -> str:
    """
    è·å–å½“å‰ç³»ç»Ÿé…ç½®

    Args:
        section: é…ç½®èŠ‚ï¼Œå¯é€‰å€¼ï¼š
            - "all": æ‰€æœ‰é…ç½®ï¼ˆé»˜è®¤ï¼‰
            - "crawler": çˆ¬è™«é…ç½®
            - "push": æ¨é€é…ç½®
            - "keywords": å…³é”®è¯é…ç½®
            - "weights": æƒé‡é…ç½®

    Returns:
        JSONæ ¼å¼çš„é…ç½®ä¿¡æ¯
    """
    tools = _get_tools()
    result = tools['config'].get_current_config(section=section)
    return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool
async def get_system_status() -> str:
    """
    è·å–ç³»ç»Ÿè¿è¡ŒçŠ¶æ€å’Œå¥åº·æ£€æŸ¥ä¿¡æ¯

    è¿”å›ç³»ç»Ÿç‰ˆæœ¬ã€æ•°æ®ç»Ÿè®¡ã€ç¼“å­˜çŠ¶æ€ç­‰ä¿¡æ¯

    Returns:
        JSONæ ¼å¼çš„ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
    """
    tools = _get_tools()
    result = tools['system'].get_system_status()
    return json.dumps(result, ensure_ascii=False, indent=2)


@mcp.tool
async def trigger_crawl(
    platforms: Optional[List[str]] = None,
    save_to_local: bool = False,
    include_url: bool = False
) -> str:
    """
    æ‰‹åŠ¨è§¦å‘ä¸€æ¬¡çˆ¬å–ä»»åŠ¡ï¼ˆå¯é€‰æŒä¹…åŒ–ï¼‰

    Args:
        platforms: æŒ‡å®šå¹³å°IDåˆ—è¡¨ï¼Œå¦‚ ['zhihu', 'weibo', 'douyin']
                   - ä¸æŒ‡å®šæ—¶ï¼šä½¿ç”¨ config.yaml ä¸­é…ç½®çš„æ‰€æœ‰å¹³å°
                   - æ”¯æŒçš„å¹³å°æ¥è‡ª config/config.yaml çš„ platforms é…ç½®
                   - æ¯ä¸ªå¹³å°éƒ½æœ‰å¯¹åº”çš„nameå­—æ®µï¼ˆå¦‚"çŸ¥ä¹"ã€"å¾®åš"ï¼‰ï¼Œæ–¹ä¾¿AIè¯†åˆ«
                   - æ³¨æ„ï¼šå¤±è´¥çš„å¹³å°ä¼šåœ¨è¿”å›ç»“æœçš„ failed_platforms å­—æ®µä¸­åˆ—å‡º
        save_to_local: æ˜¯å¦ä¿å­˜åˆ°æœ¬åœ° output ç›®å½•ï¼Œé»˜è®¤ False
        include_url: æ˜¯å¦åŒ…å«URLé“¾æ¥ï¼Œé»˜è®¤Falseï¼ˆèŠ‚çœtokenï¼‰

    Returns:
        JSONæ ¼å¼çš„ä»»åŠ¡çŠ¶æ€ä¿¡æ¯ï¼ŒåŒ…å«ï¼š
        - platforms: æˆåŠŸçˆ¬å–çš„å¹³å°åˆ—è¡¨
        - failed_platforms: å¤±è´¥çš„å¹³å°åˆ—è¡¨ï¼ˆå¦‚æœ‰ï¼‰
        - total_news: çˆ¬å–çš„æ–°é—»æ€»æ•°
        - data: æ–°é—»æ•°æ®

    Examples:
        - ä¸´æ—¶çˆ¬å–: trigger_crawl(platforms=['zhihu'])
        - çˆ¬å–å¹¶ä¿å­˜: trigger_crawl(platforms=['weibo'], save_to_local=True)
        - ä½¿ç”¨é»˜è®¤å¹³å°: trigger_crawl()  # çˆ¬å–config.yamlä¸­é…ç½®çš„æ‰€æœ‰å¹³å°
    """
    tools = _get_tools()
    result = tools['system'].trigger_crawl(platforms=platforms, save_to_local=save_to_local, include_url=include_url)
    return json.dumps(result, ensure_ascii=False, indent=2)


# ==================== å¯åŠ¨å…¥å£ ====================

def run_server(
    project_root: Optional[str] = None,
    transport: str = 'stdio',
    host: str = '0.0.0.0',
    port: int = 3333
):
    """
    å¯åŠ¨ MCP æœåŠ¡å™¨

    Args:
        project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        transport: ä¼ è¾“æ¨¡å¼ï¼Œ'stdio' æˆ– 'http'
        host: HTTPæ¨¡å¼çš„ç›‘å¬åœ°å€ï¼Œé»˜è®¤ 0.0.0.0
        port: HTTPæ¨¡å¼çš„ç›‘å¬ç«¯å£ï¼Œé»˜è®¤ 3333
    """
    # åˆå§‹åŒ–å·¥å…·å®ä¾‹
    _get_tools(project_root)

    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print()
    print("=" * 60)
    print("  TrendRadar MCP Server - FastMCP 2.0")
    print("=" * 60)
    print(f"  ä¼ è¾“æ¨¡å¼: {transport.upper()}")

    if transport == 'stdio':
        print("  åè®®: MCP over stdio (æ ‡å‡†è¾“å…¥è¾“å‡º)")
        print("  è¯´æ˜: é€šè¿‡æ ‡å‡†è¾“å…¥è¾“å‡ºä¸ MCP å®¢æˆ·ç«¯é€šä¿¡")
    elif transport == 'http':
        print(f"  ç›‘å¬åœ°å€: http://{host}:{port}")
        print(f"  HTTPç«¯ç‚¹: http://{host}:{port}/mcp")
        print("  åè®®: MCP over HTTP (ç”Ÿäº§ç¯å¢ƒ)")
        if SERVER_PASSWORD:
            print(f"  ğŸ” è®¤è¯çŠ¶æ€: âœ… å¯ç”¨")
            print(f"  ğŸ”‘ è®¿é—®å¯†ç : å·²è®¾ç½® (é•¿åº¦: {len(SERVER_PASSWORD)} å­—ç¬¦)")
            print(f"  ğŸ“ è®¿é—®æ–¹å¼:")
            print(f"     1. URLå‚æ•°: http://{host}:{port}/mcp?pwd=<your_password>")
            print(f"     2. è¯·æ±‚å¤´: curl -H 'X-MCP-Password: <your_password>' http://{host}:{port}/mcp")
        else:
            print(f"  ğŸ”“ è®¤è¯çŠ¶æ€: âŒ å…³é—­ (æœªè®¾ç½®MCP_SERVER_PASSWORDç¯å¢ƒå˜é‡)")

    if project_root:
        print(f"  é¡¹ç›®ç›®å½•: {project_root}")
    else:
        print("  é¡¹ç›®ç›®å½•: å½“å‰ç›®å½•")

    print()
    print("  å·²æ³¨å†Œçš„å·¥å…·:")
    print("    === åŸºç¡€æ•°æ®æŸ¥è¯¢ï¼ˆP0æ ¸å¿ƒï¼‰===")
    print("    1. get_latest_news        - è·å–æœ€æ–°æ–°é—»")
    print("    2. get_news_by_date       - æŒ‰æ—¥æœŸæŸ¥è¯¢æ–°é—»ï¼ˆæ”¯æŒè‡ªç„¶è¯­è¨€ï¼‰")
    print("    3. get_trending_topics    - è·å–è¶‹åŠ¿è¯é¢˜")
    print()
    print("    === æ™ºèƒ½æ£€ç´¢å·¥å…· ===")
    print("    4. search_news                  - ç»Ÿä¸€æ–°é—»æœç´¢ï¼ˆå…³é”®è¯/æ¨¡ç³Š/å®ä½“ï¼‰")
    print("    5. search_related_news_history  - å†å²ç›¸å…³æ–°é—»æ£€ç´¢")
    print()
    print("    === é«˜çº§æ•°æ®åˆ†æ ===")
    print("    6. analyze_topic_trend      - ç»Ÿä¸€è¯é¢˜è¶‹åŠ¿åˆ†æï¼ˆçƒ­åº¦/ç”Ÿå‘½å‘¨æœŸ/çˆ†ç«/é¢„æµ‹ï¼‰")
    print("    7. analyze_data_insights    - ç»Ÿä¸€æ•°æ®æ´å¯Ÿåˆ†æï¼ˆå¹³å°å¯¹æ¯”/æ´»è·ƒåº¦/å…³é”®è¯å…±ç°ï¼‰")
    print("    8. analyze_sentiment        - æƒ…æ„Ÿå€¾å‘åˆ†æ")
    print("    9. find_similar_news        - ç›¸ä¼¼æ–°é—»æŸ¥æ‰¾")
    print("    10. generate_summary_report - æ¯æ—¥/æ¯å‘¨æ‘˜è¦ç”Ÿæˆ")
    print()
    print("    === é…ç½®ä¸ç³»ç»Ÿç®¡ç† ===")
    print("    11. get_current_config      - è·å–å½“å‰ç³»ç»Ÿé…ç½®")
    print("    12. get_system_status       - è·å–ç³»ç»Ÿè¿è¡ŒçŠ¶æ€")
    print("    13. trigger_crawl           - æ‰‹åŠ¨è§¦å‘çˆ¬å–ä»»åŠ¡")
    print("=" * 60)
    print()

    # æ ¹æ®ä¼ è¾“æ¨¡å¼è¿è¡ŒæœåŠ¡å™¨
    if transport == 'stdio':
        mcp.run(transport='stdio')
    elif transport == 'http':
        # HTTP æ¨¡å¼ï¼ˆç”Ÿäº§æ¨èï¼‰
        mcp.run(
            transport='http',
            host=host,
            port=port,
            path='/mcp'  # HTTP ç«¯ç‚¹è·¯å¾„
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ä¼ è¾“æ¨¡å¼: {transport}")


if __name__ == '__main__':
    import sys
    import argparse

    parser = argparse.ArgumentParser(
        description='TrendRadar MCP Server - æ–°é—»çƒ­ç‚¹èšåˆ MCP å·¥å…·æœåŠ¡å™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # STDIO æ¨¡å¼ï¼ˆç”¨äº Cherry Studioï¼‰
  uv run python mcp_server/server.py

  # HTTP æ¨¡å¼ï¼ˆé€‚åˆè¿œç¨‹è®¿é—®ï¼‰
  uv run python mcp_server/server.py --transport http --port 3333

Cherry Studio é…ç½®ç¤ºä¾‹:
  è®¾ç½® > MCP Servers > æ·»åŠ æœåŠ¡å™¨
  - åç§°: TrendRadar
  - ç±»å‹: STDIO
  - å‘½ä»¤: [UVçš„å®Œæ•´è·¯å¾„]
  - å‚æ•°: --directory [é¡¹ç›®è·¯å¾„] run python mcp_server/server.py

è¯¦ç»†é…ç½®æ•™ç¨‹è¯·æŸ¥çœ‹: README-Cherry-Studio.md
        """
    )
    parser.add_argument(
        '--transport',
        choices=['stdio', 'http'],
        default='stdio',
        help='ä¼ è¾“æ¨¡å¼ï¼šstdio (é»˜è®¤) æˆ– http (ç”Ÿäº§ç¯å¢ƒ)'
    )
    parser.add_argument(
        '--host',
        default='0.0.0.0',
        help='HTTPæ¨¡å¼çš„ç›‘å¬åœ°å€ï¼Œé»˜è®¤ 0.0.0.0'
    )
    parser.add_argument(
        '--port',
        type=int,
        default=3333,
        help='HTTPæ¨¡å¼çš„ç›‘å¬ç«¯å£ï¼Œé»˜è®¤ 3333'
    )
    parser.add_argument(
        '--project-root',
        help='é¡¹ç›®æ ¹ç›®å½•è·¯å¾„'
    )

    args = parser.parse_args()

    run_server(
        project_root=args.project_root,
        transport=args.transport,
        host=args.host,
        port=args.port
    )
